{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load as torch model\n",
    "\n",
    "Loads the base neural network model and the `sim_to_nn` transformers from their respective files. They are combined to create a `TransformedModel` and tested on a small set of simulation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(dotenv_path=\".env\")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/30 11:16:22 INFO mlflow.tracking.fluent: Experiment with name 'lcls-injector-ML' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://mlflow-bucket/5', creation_time=1746036982208, experiment_id='5', last_update_time=1746036982208, lifecycle_stage='active', name='lcls-injector-ML', tags={}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(os.environ['MLFLOW_TRACKING_URI'])\n",
    "mlflow.set_experiment(\"lcls-injector-ML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T12:20:23.809750Z",
     "start_time": "2023-04-26T12:20:21.653781Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load base model and transformers\n",
    "model = torch.load(\"model/model.pt\")\n",
    "input_sim_to_nn = torch.load(\"model/input_sim_to_nn.pt\")\n",
    "output_sim_to_nn = torch.load(\"model/output_sim_to_nn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transformed model class\n",
    "class TransformedModel(torch.nn.Module):\n",
    "    def __init__(self, model, input_transformer, output_transformer):\n",
    "        super(TransformedModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.input_transformer = input_transformer\n",
    "        self.output_transformer = output_transformer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_transformer(x)\n",
    "        x = self.model(x)\n",
    "        x = self.output_transformer.untransform(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformedModel(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=100, bias=True)\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): Linear(in_features=100, out_features=200, bias=True)\n",
       "    (3): ELU(alpha=1.0)\n",
       "    (4): Dropout(p=0.05, inplace=False)\n",
       "    (5): Linear(in_features=200, out_features=200, bias=True)\n",
       "    (6): ELU(alpha=1.0)\n",
       "    (7): Dropout(p=0.05, inplace=False)\n",
       "    (8): Linear(in_features=200, out_features=300, bias=True)\n",
       "    (9): ELU(alpha=1.0)\n",
       "    (10): Dropout(p=0.05, inplace=False)\n",
       "    (11): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (12): ELU(alpha=1.0)\n",
       "    (13): Dropout(p=0.05, inplace=False)\n",
       "    (14): Linear(in_features=300, out_features=200, bias=True)\n",
       "    (15): ELU(alpha=1.0)\n",
       "    (16): Dropout(p=0.05, inplace=False)\n",
       "    (17): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (18): ELU(alpha=1.0)\n",
       "    (19): Dropout(p=0.05, inplace=False)\n",
       "    (20): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (21): ELU(alpha=1.0)\n",
       "    (22): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (23): ELU(alpha=1.0)\n",
       "    (24): Linear(in_features=100, out_features=5, bias=True)\n",
       "  )\n",
       "  (input_transformer): AffineInputTransform()\n",
       "  (output_transformer): AffineInputTransform()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create transformed model\n",
    "transformed_model = TransformedModel(\n",
    "    model=model, \n",
    "    input_transformer=input_sim_to_nn,\n",
    "    output_transformer=output_sim_to_nn,\n",
    ").to(torch.double)\n",
    "transformed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.38.5-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting botocore<1.39.0,>=1.38.5 (from boto3)\n",
      "  Downloading botocore-1.38.5-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.13.0,>=0.12.0 (from boto3)\n",
      "  Downloading s3transfer-0.12.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /sdf/sw/epics/package/anaconda/envs/python3.10envs/v1.1/lib/python3.10/site-packages (from botocore<1.39.0,>=1.38.5->boto3) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /sdf/sw/epics/package/anaconda/envs/python3.10envs/v1.1/lib/python3.10/site-packages (from botocore<1.39.0,>=1.38.5->boto3) (1.26.19)\n",
      "Requirement already satisfied: six>=1.5 in /sdf/sw/epics/package/anaconda/envs/python3.10envs/v1.1/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.39.0,>=1.38.5->boto3) (1.16.0)\n",
      "Downloading boto3-1.38.5-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.38.5-py3-none-any.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading s3transfer-0.12.0-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.38.5 botocore-1.38.5 jmespath-1.0.1 s3transfer-0.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/30 11:31:23 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/04/30 11:31:23 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "\u001b[31m2025/04/30 11:31:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/04/30 11:31:35 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run lcls-injector-ML Run3 at: https://ard-mlflow.slac.stanford.edu/#/experiments/5/runs/d21974393d9c49b8a5ec4f221c1f4e60\n",
      "🧪 View experiment at: https://ard-mlflow.slac.stanford.edu/#/experiments/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/30 11:31:36 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    }
   ],
   "source": [
    "# load example data and calculate predictions\n",
    "import torch.nn.functional as F\n",
    "\n",
    "with mlflow.start_run(run_name=\"lcls-injector-ML Run3\"):\n",
    "    mlflow.log_param(\"model_type\", str(type(model)))\n",
    "    mlflow.log_param(\"input_transformer_type\", str(type(input_sim_to_nn)))\n",
    "    mlflow.log_param(\"output_transformer_type\", str(type(output_sim_to_nn)))\n",
    "    \n",
    "    # Load input/output data\n",
    "    inputs_small = torch.load(\"info/inputs_small.pt\")\n",
    "    outputs_small = torch.load(\"info/outputs_small.pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = transformed_model(inputs_small)\n",
    "\n",
    "    mae = torch.mean(torch.abs(predictions - outputs_small)).item()\n",
    "    mlflow.log_metric(\"mean_absolute_error\", mae)\n",
    "    mlflow.pytorch.log_model(transformed_model, artifact_path=\"transformed_model\")\n",
    "\n",
    "    # Plot predictions vs ground truth\n",
    "    nrows, ncols = 3, 2\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10, 15))\n",
    "    for i in range(nrows * ncols):\n",
    "        ax_i = ax[i // ncols, i % ncols]\n",
    "        if i < outputs_small.shape[1]:\n",
    "            sort_idx = torch.argsort(outputs_small[:, i])\n",
    "            x_axis = torch.arange(outputs_small.shape[0])\n",
    "            ax_i.plot(x_axis, outputs_small[sort_idx, i], \"C0x\", label=\"outputs\")\n",
    "            ax_i.plot(x_axis, predictions[sort_idx, i], \"C1x\", label=\"predictions\")\n",
    "            ax_i.legend()\n",
    "    ax[-1, -1].axis('off')\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save and log plot\n",
    "    plot_path = \"comparison_plot.png\"\n",
    "    plt.savefig(plot_path)\n",
    "    mlflow.log_artifact(plot_path)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run mercurial-horse-202 at: https://ard-mlflow.slac.stanford.edu/#/experiments/5/runs/75f39c7e5c8441299256edb716d21717\n",
      "🧪 View experiment at: https://ard-mlflow.slac.stanford.edu/#/experiments/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/30 11:31:16 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/04/30 11:31:16 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "if mlflow.active_run() is not None:\n",
    "    mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
