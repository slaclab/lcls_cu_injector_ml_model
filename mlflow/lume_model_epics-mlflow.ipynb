{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load as LUME-model for use with EPICS data\n",
    "\n",
    "Loads the base neural network model, the `sim_to_nn` & `pv_to_sim` transformers and the PV variable specification from their respective files to create a [LUME-model](https://github.com/slaclab/lume-model/). The resulting instance of `TorchModel` enforces requirements on the input and output variables and can be wrapped in a `TorchModule`. The `TorchModule` can be used like a `torch.nn.Module` and is tested on a small set of data.\n",
    "\n",
    "When working with EPICS PV data, it's important to remember that the data you pull from the archive will require some post-processing before it can be used with the surrogate model below. \n",
    "\n",
    "For example:\n",
    "* outliers may need to be removed\n",
    "* unphysical values may need to be removed (e.g. XRMS and YRMS values below 0)\n",
    "* values for features that lie outside the training distribution should be removed\n",
    "* values for unmeasurable PVs (such as the pulse length) will need to be imputed (`Pulse_length`)\n",
    "* values for features that were not varied in the training data will need to be overwritten with the PV unit equivalent of the value used during training (`FBCK:BCI0:1:CHRG_S` and `ACCL:IN20:400:L0B_ADES`)\n",
    "* compound PVs (PVs created from a calculation using measured PVs) will need to be calculated (`CAMR:IN20:186:R_DIST`)\n",
    "\n",
    "`CAMR:IN20:186:R_DIST` is calculated from `CAMR:IN20:186:XRMS` and `CAMR:IN20:186:YRMS` using the following formula:\n",
    "```python\n",
    "r_dist = np.sqrt(data[\"CAMR:IN20:186:XRMS\"].values ** 2 + data[\"CAMR:IN20:186:YRMS\"].values ** 2)\n",
    "```\n",
    "\n",
    "Further information about the specific changes that need to be applied for this model can be found in the [README](README.md) and the [PV variable specification](model/pv_variables.yml). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T12:20:23.809750Z",
     "start_time": "2023-04-26T12:20:21.653781Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import mlflow\n",
    "\n",
    "from lume_model.utils import variables_from_yaml\n",
    "from lume_model.models import TorchModel, TorchModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\".env\")         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://mlflow-bucket/5', creation_time=1746036982208, experiment_id='5', last_update_time=1746036982208, lifecycle_stage='active', name='lcls-injector-ML', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(os.environ['MLFLOW_TRACKING_URI'])\n",
    "mlflow.set_experiment(\"lcls-injector-ML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/02 10:16:19 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/05/02 10:16:19 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "mlflow.start_run(run_name=\"lume_model_epics Run2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AffineInputTransform -> AffineInputTransform'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load sim_to_nn transformers\n",
    "input_sim_to_nn = torch.load(\"../model/input_sim_to_nn.pt\")\n",
    "output_sim_to_nn = torch.load(\"../model/output_sim_to_nn.pt\")\n",
    "\n",
    "# load pv_to_sim transformers\n",
    "input_pv_to_sim = torch.load('../model/input_pv_to_sim.pt')\n",
    "output_pv_to_sim = torch.load('../model/output_pv_to_sim.pt')\n",
    "\n",
    "mlflow.log_param(\"input_transformers\", f\"{type(input_pv_to_sim).__name__} -> {type(input_sim_to_nn).__name__}\")\n",
    "mlflow.log_param(\"output_transformers\", f\"{type(output_sim_to_nn).__name__} -> {type(output_pv_to_sim).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in- and output variable specification\n",
    "input_variables, output_variables = variables_from_yaml(\"../model/pv_variables.yml\")\n",
    "\n",
    "mlflow.log_param(\"input_variables\", input_variables)\n",
    "mlflow.log_param(\"output_variables\", output_variables)\n",
    "mlflow.log_artifact(\"../model/pv_variables.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded PyTorch model from file: ../model/model.pt\n",
      "Loaded PyTorch model from file: /sdf/home/g/gopikab/lcls-ml/lcls_cu_injector_ml_model/model/model.pt\n"
     ]
    }
   ],
   "source": [
    "# create TorchModel\n",
    "lume_model = TorchModel(\n",
    "    model=\"../model/model.pt\",\n",
    "    input_variables=input_variables,\n",
    "    output_variables=output_variables,\n",
    "    input_transformers=[input_pv_to_sim, input_sim_to_nn],  # pv_to_sim before sim_to_nn\n",
    "    output_transformers=[output_sim_to_nn, output_pv_to_sim],  # sim_to_nn before pv_to_sim\n",
    ")\n",
    "\n",
    "# or simply load from YAML file\n",
    "lume_model = TorchModel(\"../model/pv_model.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded PyTorch model from file: /sdf/home/g/gopikab/lcls-ml/lcls_cu_injector_ml_model/model/model.pt\n"
     ]
    }
   ],
   "source": [
    "# wrap in TorchModule\n",
    "lume_module = TorchModule(\n",
    "    model=lume_model,\n",
    "    input_order=lume_model.input_names,\n",
    "    output_order=lume_model.output_names,\n",
    ")\n",
    "\n",
    "# or simply load from YAML file\n",
    "lume_module = TorchModule(\"../model/pv_module.yml\")\n",
    "\n",
    "mlflow.log_artifact(\"../model/pv_module.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load example data and calculate predictions\n",
    "inputs_small = input_pv_to_sim.untransform(torch.load(\"../info/inputs_small.pt\"))\n",
    "outputs_small = output_pv_to_sim.untransform(torch.load(\"../info/outputs_small.pt\"))\n",
    "with torch.no_grad():\n",
    "    predictions = lume_module(inputs_small)\n",
    "# Log performance metric\n",
    "mae = torch.mean(torch.abs(predictions - outputs_small)).item()\n",
    "mlflow.log_metric(\"mean_absolute_error\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot example data and predictions\n",
    "nrows, ncols = 3, 2\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10, 15))\n",
    "for i, output_name in enumerate(lume_module.output_order):\n",
    "    ax_i = ax[i // ncols, i % ncols]\n",
    "    if i < outputs_small.shape[1]:\n",
    "        sort_idx = torch.argsort(outputs_small[:, i])\n",
    "        x_axis = torch.arange(outputs_small.shape[0])\n",
    "        ax_i.plot(x_axis, outputs_small[sort_idx, i], \"C0x\", label=\"outputs\")\n",
    "        ax_i.plot(x_axis, predictions[sort_idx, i], \"C1x\", label=\"predictions\")\n",
    "        ax_i.legend()\n",
    "        ax_i.set_title(output_name)\n",
    "ax[-1, -1].axis('off')\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "plot_path = \"epics_plot_lume.png\"\n",
    "plt.savefig(plot_path)\n",
    "mlflow.log_artifact(plot_path)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Output PVs\n",
    "\n",
    "If we have missing outputs, for example outputs of the model that are not measured in EPICS, we can simply remove these from the `TorchModule` by passing a truncated list to `output_order` (they still need to be listed in the TorchModel though)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OTRS:IN20:571:XRMS', 'OTRS:IN20:571:YRMS']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wrap in truncated TorchModule\n",
    "truncated_lume_module = TorchModule(\n",
    "    model=lume_model,\n",
    "    input_order=lume_model.input_names,\n",
    "    output_order=lume_model.output_names[0:2],  # truncate list of parameters\n",
    ")\n",
    "truncated_lume_module.output_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([283, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predictions\n",
    "with torch.no_grad():\n",
    "    predictions = truncated_lume_module(inputs_small)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot example data and predictions\n",
    "nrows, ncols = 1, 2\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10, 5))\n",
    "for i, output_name in enumerate(truncated_lume_module.output_order):\n",
    "    sort_idx = torch.argsort(outputs_small[:, i])\n",
    "    x_axis = torch.arange(outputs_small.shape[0])\n",
    "    ax[i].plot(x_axis, outputs_small[sort_idx, i], \"C0x\", label=\"outputs\")\n",
    "    ax[i].plot(x_axis, predictions[sort_idx, i], \"C1x\", label=\"predictions\")\n",
    "    ax[i].legend()\n",
    "    ax[i].set_title(output_name)\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "plot_path = \"epics_lume.png\"\n",
    "plt.savefig(plot_path)\n",
    "mlflow.log_artifact(plot_path)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/02 10:37:05 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run lume_model_epics Run2 at: https://ard-mlflow.slac.stanford.edu/#/experiments/5/runs/96458aef9537417d92e69e33d74bf777\n",
      "🧪 View experiment at: https://ard-mlflow.slac.stanford.edu/#/experiments/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/02 10:37:05 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    }
   ],
   "source": [
    "if mlflow.active_run():\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
